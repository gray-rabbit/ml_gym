{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_1 (Sequential)   (None, 1280)              410208    \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 2)                 128300    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 538,508\n",
      "Trainable params: 524,428\n",
      "Non-trainable params: 14,080\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.layers.pooling.GlobalAveragePooling2D at 0x1af8f253610>,\n",
       " <keras.layers.core.dense.Dense at 0x1af8fb20460>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'sequential_1_input')>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\python_workspace\\ml_gym\\06_teachable.ipynb 셀 5\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python_workspace/ml_gym/06_teachable.ipynb#ch0000004?line=2'>3</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(img, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python_workspace/ml_gym/06_teachable.ipynb#ch0000004?line=3'>4</a>\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m,\u001b[39m224\u001b[39m,\u001b[39m224\u001b[39m,\u001b[39m3\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/python_workspace/ml_gym/06_teachable.ipynb#ch0000004?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39mpredict(img)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python_workspace/ml_gym/06_teachable.ipynb#ch0000004?line=5'>6</a>\u001b[0m cam\u001b[39m.\u001b[39mrelease()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"test.png\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = img.reshape(1,224,224,3)\n",
    "model.predict(img)\n",
    "cam.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\python_workspace\\ml_gym\\06_teachable.ipynb 셀 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/python_workspace/ml_gym/06_teachable.ipynb#ch0000005?line=0'>1</a>\u001b[0m cam \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python_workspace/ml_gym/06_teachable.ipynb#ch0000005?line=1'>2</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/python_workspace/ml_gym/06_teachable.ipynb#ch0000005?line=2'>3</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m cam\u001b[39m.\u001b[39mread()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    img = cv2.resize(frame, (224,224),interpolation=cv2.INTER_LINEAR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img/127.0-1\n",
    "    predict = model.predict(img.reshape(1,224,224,3))\n",
    "    idx = np.argmax(predict,1)\n",
    "    cv2.putText(frame,\"predict: \"+str(idx),(30,30),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),4)\n",
    "    cv2.imshow(\"img\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key ==ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n",
      "tpdlqn\n"
     ]
    }
   ],
   "source": [
    "## 티쳐블 머신!? 직접 만들면 되지 뭐!!\n",
    "\n",
    "## 1단계 이미지 찍기\n",
    "cam = cv2.VideoCapture(0)\n",
    "class1_idx=0\n",
    "class2_idx=0\n",
    "class3_idx=0\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    ret, bin = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
    "    cv2.imshow(\"bin\", bin)\n",
    "    save_image = cv2.resize(bin, (224,224),interpolation=cv2.INTER_LINEAR)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('1'):\n",
    "        cv2.imwrite(f\"./images/class_a/class1_{class1_idx}.png\",save_image);\n",
    "        class1_idx+=1\n",
    "    if key == ord('2'):\n",
    "        cv2.imwrite(f\"./images/class_b/class2_{class2_idx}.png\",save_image);\n",
    "        class2_idx+=1\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77 files belonging to 2 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                501770    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 501,792\n",
      "Trainable params: 501,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "imgs = keras.utils.image_dataset_from_directory(\"./images/\",color_mode=\"grayscale\", image_size=(224,224),label_mode=\"categorical\")\n",
    "model = tf.keras.Sequential(\n",
    "    [tf.keras.layers.Flatten(input_shape=(224, 224)),\n",
    "     tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "     tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
    "     ]\n",
    ")\n",
    "model.summary()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 513.5112\n",
      "Epoch 2/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 525.5002\n",
      "Epoch 3/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 203.4170\n",
      "Epoch 4/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 93.1721\n",
      "Epoch 5/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 75.0738\n",
      "Epoch 6/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 39.1229\n",
      "Epoch 7/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5129\n",
      "Epoch 8/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5128\n",
      "Epoch 9/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5127\n",
      "Epoch 10/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5126\n",
      "Epoch 11/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5126\n",
      "Epoch 12/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5125\n",
      "Epoch 13/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5124\n",
      "Epoch 14/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5125\n",
      "Epoch 15/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5124\n",
      "Epoch 16/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5123\n",
      "Epoch 17/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5121\n",
      "Epoch 18/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5118\n",
      "Epoch 19/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5117\n",
      "Epoch 20/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5116\n",
      "Epoch 21/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5114\n",
      "Epoch 22/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5112\n",
      "Epoch 23/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5111\n",
      "Epoch 24/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5110\n",
      "Epoch 25/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5108\n",
      "Epoch 26/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5107\n",
      "Epoch 27/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5106\n",
      "Epoch 28/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5104\n",
      "Epoch 29/40\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5103\n",
      "Epoch 30/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5102\n",
      "Epoch 31/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5101\n",
      "Epoch 32/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5100\n",
      "Epoch 33/40\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.5098\n",
      "Epoch 34/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5097\n",
      "Epoch 35/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5096\n",
      "Epoch 36/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5095\n",
      "Epoch 37/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5094\n",
      "Epoch 38/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5092\n",
      "Epoch 39/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5091\n",
      "Epoch 40/40\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19805c62280>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(imgs, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    img = cv2.resize(frame, (224,224),interpolation=cv2.INTER_LINEAR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    ret, bin = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
    "    save_image = cv2.resize(bin, (224,224),interpolation=cv2.INTER_LINEAR)\n",
    "    predict = model.predict(save_image.reshape(1,224,224))\n",
    "    idx = np.argmax(predict,1)\n",
    "    cv2.putText(frame,\"predict: \"+str(idx),(30,30),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),4)\n",
    "    cv2.imshow(\"img\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key ==ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml_gym': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6ac081869b530f457619791f617d77cf805282e7db014faab8a21ecdc256c9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
